# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10FJSM8By3fKo9uTnUANIB2WQRf8Vb5mV

# Anime Recommendation System

![anime](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11299784%2Fcaaff69976c0a1e97c7d55eb82383680%2Fstatic-assets-upload6207184415643227018.jpg?generation=1686492418151095&alt=media)

## Data Collection
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score

!pip install -q kaggle

"""Anime Dataset 2023 [Unduh Datasets](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset/data?select=anime-filtered.csv)"""

!kaggle datasets download -d dbdmobile/myanimelist-dataset

"""## Data Understanding"""

path = '/content/drive/MyDrive/Submission Dicoding Sistem Rekomendasi/myanimelist-dataset.zip'
extract_to = '/content'

import zipfile

with zipfile.ZipFile(path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

anime_data = pd.read_csv('/content/anime-dataset-2023.csv')
user_detail = pd.read_csv('/content/users-details-2023.csv')
user_rating = pd.read_csv('/content/users-score-2023.csv')

anime_data.head()

"""**(anime-dataset-2023.csv)** Dataset ini mencakup informasi utama tentang judul anime, seperti ID unik, judul (dalam bahasa asli dan bahasa Inggris), nama alternatif, skor, genre, sinopsis, jenis, jumlah episode, tanggal penayangan, musim perdana, status, studio produksi, lisensor, sumber materi, durasi episode, rating umur, peringkat, popularitas, jumlah favorit, jumlah pengguna yang memberikan skor, jumlah anggota, dan URL gambar. Dataset ini dapat digunakan untuk menganalisis dan memahami karakteristik anime, penilaian, popularitas, dan keterlibatan penonton."""

print(f'Terdapat  {anime_data.shape[0]} Table dan {anime_data.shape[1]} columns untuk dataset anime-dataset-2023.')

user_detail.head()

"""**(users-details-2023.csv)** Dataset ini menyimpan informasi tentang pengguna di platform, termasuk ID unik, nama pengguna, jenis kelamin, tanggal lahir (format ISO), lokasi, tanggal bergabung (format ISO), total hari menonton anime, skor rata-rata yang diberikan, jumlah anime yang sedang ditonton, yang telah selesai ditonton, yang ditunda, yang dihentikan, yang direncanakan untuk ditonton, total entri anime, jumlah rewatch, dan total episode yang telah ditonton. Dataset ini menyediakan informasi berharga untuk menganalisis perilaku dan preferensi pengguna di platform anime."""

print(f'Terdapat  {user_detail.shape[0]} Table dan {user_detail.shape[1]} columns untuk dataset anime-dataset-2023.')

user_rating.head()

"""**(users-score-2023.csv)** Dataset ini memuat interaksi pengguna dengan anime, termasuk ID pengguna, nama pengguna, ID anime, judul anime, dan rating yang diberikan oleh pengguna untuk anime tersebut. Dataset ini memungkinkan berbagai analisis dan wawasan mengenai interaksi pengguna dengan anime. Dengan memeriksa skor pengguna untuk berbagai judul anime, kita dapat mengidentifikasi anime yang memiliki rating tinggi dan populer di kalangan pengguna. Selain itu, preferensi pengguna dan pola tontonan untuk judul anime tertentu dapat dieksplorasi. Dataset ini juga menjadi dasar untuk membangun sistem rekomendasi berbasis rating pengguna, membantu menyarankan anime yang sesuai dengan selera masing-masing individu. Lebih jauh lagi, kita dapat melakukan filtering kolaboratif dan analisis kesamaan untuk menemukan pola minat pengguna yang serupa."""

print(f'Terdapat  {user_rating.shape[0]} Table dan {user_rating.shape[1]} columns untuk dataset anime-dataset-2023.')

print('Jumlah data anime dataset: ', len(anime_data.anime_id	.unique()))
print('Jumlah data users details: ', len(user_detail['Mal ID'].unique()))
print('Jumlah data users score: ', len(user_rating.anime_id	.unique()))

"""Untuk Content Based Filtering (dengan Filter Genres) disini kita akan menggunakan dataset **anime-dataset-2023.csv**

## Exploratory Data Analysis - Deskripsi Variabel

Variabel-variabel pada anime-dataset-2024 adalah sebagai berikut:

- **anime_id**: ID unik untuk setiap anime.  
- **Name**: Nama anime dalam bahasa aslinya.  
- **English name**: Nama anime dalam bahasa Inggris.  
- **Other name**: Nama asli atau judul dari anime (dapat berupa bahasa Jepang,  
   Cina, atau Korea).  
- **Score**: Skor atau rating yang diberikan untuk anime.  
- **Genres**: Genre anime, dipisahkan dengan koma.  
- **Synopsis**: Deskripsi singkat atau ringkasan cerita dari anime.  
- **Type**: Jenis dari anime (misalnya, TV series, movie, OVA, dll.).  
- **Episodes**: Jumlah episode dalam anime.  
- **Aired**: Tanggal saat anime ditayangkan.  
- **Premiered**: Musim dan tahun ketika anime pertama kali tayang.  
- **Status**: Status anime (misalnya, Finished Airing, Currently Airing,  
  dll.).  
- **Producers**: Perusahaan produksi atau produser dari anime.  
- **Licensors**: Pemberi lisensi anime (misalnya, platform streaming).  
- **Studios**: Studio animasi yang mengerjakan anime tersebut.  
- **Source**: Sumber materi dari anime (misalnya, manga, light novel, original).  
- **Duration**: Durasi setiap episode.  
- **Rating**: Rating usia dari anime.  
- **Rank**: Peringkat anime berdasarkan popularitas atau kriteria lainnya.  
- **Popularity**: Peringkat popularitas dari anime.  
- **Favorites**: Jumlah kali anime ditandai sebagai favorit oleh pengguna.  
- **Scored By**: Jumlah pengguna yang memberi skor untuk anime tersebut.  
- **Members**: Jumlah anggota yang menambahkan anime ke daftar mereka di platform.  
- **Image URL**: URL gambar atau poster dari anime.

### Genres Variable

eksplorasi variabel Genres, yaitu Genres anime yang tersedia. Mari kita lihat info variabel Genres dengan menggunakan fungsi info().
"""

anime_data['Genres'].info()

print('Banyak Jenis Genres yang ada: ', len(anime_data['Genres'].unique()))
print('Jenis Genres yang ada: ', anime_data['Genres'].unique())

"""### Profile

rofile pengguna kadang diperlukan untuk memahami pola preferensi terhadap suatu item. Pertama, kita lihat terlebih dahulu berapa jumlah kolom dan baris pada dataset **users-details.csv**.
"""

print(user_detail.shape)

"""Selanjutnya, mari kita lihat fitur apa saja yang terdapat di user_detail. Implementasikan kode berikut."""

user_detail.head()

"""### Rating

eksplorasi data yang akan kita gunakan pada model yaitu data user_score. Pertama, kita lihat seperti apa data pada user_score dengan fungsi head()
"""

user_rating.head()

"""Dari fungsi user_rating.head(), kita dapat mengetahui bahwa data user_score terdiri dari 5 kolom dengan. Kolom-kolom tersebut antara lain:

- **user_id:** ID unik untuk setiap pengguna.
- **Username:** Nama pengguna di platform.
- **anime_id:** ID unik untuk setiap anime.
- **Anime Title:** Judul anime.
- **rating:** Rating yang diberikan oleh pengguna untuk anime tersebut.

Nah, untuk melihat distribusi rating pada data, gunakan fungsi describe() dengan menerapkan kode berikut:
"""

user_rating.describe()

"""Dari output di atas, diketahui bahwa nilai maksimum rating adalah 10 dan nilai minimumnya adalah 1. Artinya, skala rating berkisar antara 1 hingga 10.

Untuk melihat berapa pengguna yang memberikan rating menggunakan kode berikut.
"""

print('Jumlah user_id: ', len(user_rating.user_id.unique()))
print('Jumlah anime_id: ', len(user_rating.anime_id.unique()))
print('Jumlah data rating: ', len(user_rating))

"""## Exploratory Data Analysis - Univariate"""

plt.figure(figsize=(15, 5))
sns.countplot(x=anime_data['Type'], data=anime_data, order=anime_data['Type'].value_counts().index, palette='Set3')
plt.title('Jumlah Type Anime ')
plt.xlabel('Type Anime')
plt.ylabel('Count')
plt.show()

"""Dari visualisasi diatas dapat dilihat pada dataset Type Anime TV menduduki jumlah paling tinggi disusul Movie dan OVA dan paling lalu ada Type anime UNKNOWN dengan jumlah paling sedikit"""

# Menghitung jumlah studios
studio_counts = anime_data['Studios'].value_counts()

# Mengelompokkan studios dengan jumlah terbanyak
top_studios = studio_counts.head(5)  # Mengambil 5 studio teratas
other_count = studio_counts.iloc[5:].sum()  # Menghitung total untuk studio lainnya
studio_counts_grouped = pd.concat([top_studios, pd.Series({'Lainnya': other_count})])  # Menggabungkan dengan pd.concat()

# Membuat pie chart
plt.figure(figsize=(15, 5))
plt.pie(studio_counts_grouped, labels=studio_counts_grouped.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set3', n_colors=len(studio_counts_grouped)))
plt.title('Distribusi Studios Anime (Top 5 + Lainnya)')
plt.axis('equal')  # Equal aspect ratio ensures that pie chart is a circle.
plt.show()

"""Pada Visualisasi Top 5 distribusi Studio Anime terbanyak pada dataset sebesar 42.3% Tidak diketahu (UNKNOWN) lalu 3,3% untuk Studio Toei Animation, 2.1% Studio Sunrise, 1.5% Studio J.C.Staff, 1.3% Shanghai Animation Film Studio dan 49.4% untuk studio lainnya."""

# Data 10 anime teratas berdasarkan jumlah members
top10_anime = anime_data.nlargest(10, 'Members')[['Name', 'Members']]

# Menggunakan palet warna dari Seaborn
colors = sns.color_palette('Set3', n_colors=10)

# Plot bar horizontal
plt.figure(figsize=(15, 5))
plt.barh(top10_anime['Name'], top10_anime['Members'], color=colors * (len(top10_anime) // len(colors) + 1), edgecolor='black')
plt.xlabel('Jumlah Members', fontsize=15)
plt.ylabel('Nama Anime', fontsize=15)
plt.title("10 Anime Teratas Berdasarkan Jumlah Members")
plt.grid(axis='x', linestyle='--', alpha=0.7)

plt.show()

"""dari visualisasi diatas dapat dilihat top 10 anime teratas berdasarkan jumlah membernya mulai dari shingeki no kyojin hingga hunter x hunter."""

# Ubah 'Score' menjadi numerik, abaikan nilai yang tidak bisa dikonversi
anime_data['Score'] = pd.to_numeric(anime_data['Score'], errors='coerce')

# Hapus baris dengan nilai NaN di kolom 'Score'
anime_data = anime_data.dropna(subset=['Score'])

# Data 10 anime teratas berdasarkan 'Score'
top10_anime = anime_data.nlargest(10, 'Score')[['Name', 'Score']]

# Menggunakan palet warna dari Seaborn
colors = sns.color_palette('Set3', n_colors=len(top10_anime))  # Mengambil warna dari palet

# Plot bar horizontal
plt.figure(figsize=(15, 5))
plt.barh(top10_anime['Name'], top10_anime['Score'], color=colors, edgecolor='black')
plt.xlabel('Score', fontsize=15)
plt.ylabel('Nama Anime', fontsize=15)
plt.title("Top 10 Anime Berdasarkan Score Paling Tinggi")
plt.grid(axis='x', linestyle='--', alpha=0.7)

plt.show()

"""dari visualisasi diatas dapat dilihat top 10 anime teratas berdasarkan skor paling tinggi jika diambil 10 teratas berdasarkan score maka hasilnya berbeda dengan 10 anime teratas berdasarkan jumlah membernya.

## Exploratory Data Analysis - Multivariate Analysis
"""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Members', 'Popularity']].corr()

print("Korelasi antara Members dan Popularity:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Popularity
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Members', y='Popularity', alpha=0.6)
plt.title('Scatter Plot of Members vs Popularity')
plt.xlabel('Members')
plt.ylabel('Popularity')
plt.show()

"""Nilai korelasi negatif sebesar -0.36 menunjukkan adanya hubungan negatif sedang antara jumlah Members dan Popularity. Ini berarti bahwa anime dengan jumlah Members yang lebih tinggi cenderung memiliki nilai Popularity yang lebih rendah."""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Favorites', 'Popularity']].corr()

print("Korelasi antara Members dan Popularity:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Popularity
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Favorites', y='Popularity', alpha=0.6)
plt.title('Scatter Plot of Favorites vs Popularity')
plt.ylabel('Favorites')
plt.xlabel('Popularity')
plt.show()

""" Nilai korelasi negatif ini menunjukkan hubungan yang lemah antara jumlah Favorites dan Popularity. Korelasi negatif berarti bahwa ketika jumlah Favorites meningkat, nilai Popularity (peringkat) cenderung menurun, meskipun hubungannya tidak kuat."""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Favorites', 'Members']].corr()

print("Korelasi antara Members dan Members:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Members
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Favorites', y='Members', alpha=0.6)
plt.title('Scatter Plot of Favorites vs Members')
plt.ylabel('Favorites')
plt.xlabel('Members')
plt.show()

"""Nilai korelasi 0.773 menunjukkan adanya hubungan positif yang kuat antara jumlah Favorites dan Members. Ini berarti bahwa anime dengan jumlah Members yang tinggi cenderung juga memiliki jumlah Favorites yang tinggi.

## Data Preprocessing

sebelumnya kita memiliki 3 file csv dan setelah di cek untuk melakukan Content Based Filtering kita cukup menggunakan dataset anime-dataset-2023 dan untuk Collaborative Filtering kita cukup menggunakan users-score-2023 yang kemudian akan kita simpan kedalam 2 data frame Anime dan Rating.

### Hapus beberapa atribut yang tidak terlalu penting pada data Anime
"""

print("Daftar Atribut:")
print(anime_data.columns.tolist())

Anime = anime_data.drop(columns=[
    'English name', 'Other name', 'Synopsis','Episodes', 'Aired', 'Premiered',
    'Status', 'Producers', 'Licensors', 'Studios', 'Source', 'Duration', 'Rating',
    'Rank', 'Popularity', 'Favorites', 'Scored By', 'Members', 'Image URL', 'Score','Type'
    ])

Anime.head()

"""### Hapus beberapa atribut yang tidak terlalu penting pada data Rating"""

print("Daftar Atribut:")
print(user_rating.columns.tolist())

Rating = user_rating.drop(columns=[
    'Anime Title',
    'Username'
])

"""karena nanti user_rating akan digabung dengan anime dimana di anime sudah terdapat atribut name untuk nama animenya maka anime title di user_rating dan username akan kita hapus."""

Rating.head()

"""## Data Preparation

### Mengatasi Missing Value
"""

# Mengecek missing value pada dataframe Anime_2023
Anime.isnull().sum()

"""output diatas dapat disimpulkan pada dataframe Anime tidak terdapat missing value."""

Anime.duplicated().sum()

"""output diatas dapat disimpulkan pada dataframe Anime tidak terdapat aata Duplicated.

### Menyamakan Anime Genres

Sebelum masuk tahap akhir (pemodelan), kita perlu mencek kembali nama type.
"""

# Mengurutkan genres anime
fix_anime = Anime.sort_values('anime_id', ascending=True)
fix_anime

"""Sekarang, kita memiliki 15692 baris data."""

# Mengecek berapa jumlah fix_anime
len(fix_anime.anime_id.unique())

"""Selanjutnya, mari kita cek genres anime yang unik dengan kode berikut."""

# Mengecek Genres yang unik
fix_anime.Genres.unique()

fix_anime[fix_anime['Genres'] == 'UNKNOWN']

"""Ternyata, ada type unknown"""

# Menghapus semua baris dengan Genres 'UNKNOWN'
fix_anime = fix_anime[fix_anime['Genres'] != 'UNKNOWN']

"""karena kita akan membangun sistem rekomendasi anime berdasarkan genre anime untuk value genres kita hapus.

## Model Development dengan Content Based Filtering
"""

fix_anime.sample(5)

"""### TF-IDF Vectorizer

seperti yang kita ketahui komputer hanya bisa memproses data numerik oleh karena itu kita perlu mengubah nilai genres menjadi numerik dengan TfidfVectorizer,
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(fix_anime['Genres'])

tf.get_feature_names_out()

"""Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks."""

tfidf_matrix = tf.fit_transform(fix_anime['Genres'])

tfidf_matrix.shape

"""matriks yang kita miliki berukuran (13939, 27). Nilai 13939 merupakan ukuran data dan 27 merupakan genres anime.

Untuk menghasilkan vektor tf-idf dalam bentuk matriks, kita menggunakan fungsi todense(). Jalankan kode berikut.
"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Selanjutnya, mari kita lihat matriks tf-idf untuk beberapa anime dan genresnya. dengan kode berikut."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=fix_anime.Name
).sample(27, axis=1).sample(10, axis=0)

"""### Cosine Similarity

selanjutnya menghitung derajat kesamaan (similarity degree) antar anime dengan teknik cosine similarity. Di sini, kita menggunakan fungsi cosine_similarity dari library sklearn dengan kode berikut.
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""tahapan ini, menghitung cosine similarity dataframe tfidf_matrix yang kita peroleh pada tahapan sebelumnya. Dengan satu baris kode untuk memanggil fungsi cosine similarity dari library sklearn, jika sudah selesai menghitung kesamaan (similarity) antar restoran. Kode di atas menghasilkan keluaran berupa matriks kesamaan dalam bentuk array."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=fix_anime['Name'], columns=fix_anime['Name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dengan cosine similarity, kita berhasil mengidentifikasi kesamaan antara satu anime dengan anime lainnya. Shape (13939, 13939) merupakan ukuran matriks similarity dari data yang kita miliki. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 13939 anime x 13939 anime (masing-masing dalam sumbu X dan Y). Artinya, kita mengidentifikasi tingkat kesamaan pada 13939 nama anime.

### Mendapatkan Rekomendasi

Sebelumnya, hasil data similarity (kesamaan) antar anime, selanjutnya  menghasilkan sejumlah anime yang akan direkomendasikan kepada pengguna.

Di sini, kita membuat fungsi anime_recommendations dengan beberapa parameter sebagai berikut:

Nama_anime : Nama anime (index kemiripan dataframe).
Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.
Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘anime_name’ dan ‘’.Genres
k : Banyak rekomendasi yang ingin diberikan.
Sebelum mulai menulis kodenya, ingatlah kembali definisi sistem rekomendasi yang menyatakan bahwa keluaran sistem ini adalah berupa top-N recommendation.
"""

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=fix_anime[['Name', 'Genres']], k=10):

    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_anime agar nama anime yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_anime, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""pada kode di atas, dengan menggunakan argpartition, kita mengambil sejumlah nilai k tertinggi dari similarity data (dalam kasus ini: dataframe cosine_sim_df). Kemudian, kita mengambil data dari bobot (tingkat kesamaan) tertinggi ke terendah. Data ini dimasukkan ke dalam variabel closest. Berikutnya, kita perlu menghapus nama_anime yang yang dicari agar tidak muncul dalam daftar rekomendasi. Dalam kasus ini, nanti kita akan mencari anime yang mirip dengan Tarareba, sehingga kita perlu drop nama_anime Tarareba agar tidak muncul dalam daftar rekomendasi yang diberikan nanti.

Selanjutnya, terapkan kode di atas untuk menemukan rekomendasi restoran yang mirip dengan KFC. Terapkan kode berikut:
"""

fix_anime[fix_anime.Name.eq('Tarareba')]

"""Hasil Output di atas, Tarareba masuk dalam Genre Drama. Tentu kita berharap rekomendasi yang diberikan adalah resto dengan kategori yang mirip. Nah, sekarang, dapatkan anime recommendation dengan memanggil fungsi yang telah kita definisikan sebelumnya:"""

anime_recommendations('Tarareba')

"""Sistem kita memberikan rekomendasi 10 anime dengan genre ‘Drama’.

## Model Development dengan Collaborative Filtering

import semua library yang dibutuhkan
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""### Data Understanding"""

# Membaca dataset

Rating

"""pada output di atas data rating memiliki 24325191 baris dan 3 kolom."""

fix_rating = Rating.sample(n=10000, random_state=42)

print(fix_rating.head())

example_rating = fix_rating.copy()
print(example_rating.head())

"""karena dataset Rating sangat banyak dan tidak sepadan dengan sumber daya yang saya miliki oleh karena itu kita akan mengambil beberap puluh ribu saja untuk dijadikan sample.

### Data Preparation

tahap preprocessing. Pada tahap ini, Anda perlu melakukan persiapan data untuk menyandikan (encode) fitur ‘user_id’ dan ‘anime_id’ ke dalam indeks integer.
"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = fix_rating['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

"""Selanjutnya, lakukan hal yang sama pada fitur ‘anime_id’."""

anime_ids = fix_rating['anime_id'].unique().tolist()

anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}

anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

"""Berikutnya, petakan user_id dan anime_id ke dataframe yang berkaitan."""

fix_rating['user'] = fix_rating['user_id'].map(user_to_user_encoded)

fix_rating['anime'] = fix_rating['anime_id'].map(anime_to_anime_encoded)

"""dan terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah anime, dan mengubah nilai rating menjadi float."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah anime
num_anime = len(anime_encoded_to_anime)
print(num_anime)

# Mengubah rating menjadi nilai float
fix_rating['rating'] = fix_rating['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(fix_rating['rating'])

# Nilai maksimal rating
max_rating = max(fix_rating['rating'])

print('Number of User: {}, Number of anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

"""Tahap persiapan telah selesai.

Memahami data rating yang kita miliki.
Menyandikan (encode) fitur ‘user’ dan ‘anime_id’ ke dalam indeks integer.
Memetakan ‘user_id’ dan ‘anime_id’ ke dataframe yang berkaitan.
Mengecek beberapa hal dalam data seperti jumlah user, jumlah anime, kemudian mengubah nilai rating menjadi float.
Tahap persiapan ini penting dilakukan agar data siap digunakan untuk pemodelan. Namun sebelumnya, kita perlu membagi data untuk training dan validasi terlebih dahulu.

### Membagi Data untuk Training dan Validasi
"""

# Mengacak dataset
fix_rating = fix_rating.sample(frac=1, random_state=42)
fix_rating

"""lalu membagi data train dan validasi dengan komposisi 80:20. Namun sebelumnya, kita perlu memetakan (mapping) data user dan anime menjadi satu value terlebih dahulu. dan membuat rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training"""

# Membuat variabel x untuk mencocokkan data user dan anime menjadi satu value
x = fix_rating[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = fix_rating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * fix_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Data telah siap untuk dimasukkan ke dalam model.

## Proses Training

tahap ini, model menghitung skor kecocokan antara pengguna dan anime dengan teknik embedding, melakukan proses embedding terhadap data user dan anime. Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan anime. Selain itu, kita juga dapat menambahkan bias untuk setiap user dan anime. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.

membuat class RecommenderNet dengan keras Model class. Kode class RecommenderNet ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang kita selesaikan. Terapkan kode berikut.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = layers.Embedding( # layer embeddings anime
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) # layer embedding anime bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    anime_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    anime_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)

    x = dot_user_anime + user_bias + anime_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, melakukan proses compile terhadap model."""

model = RecommenderNet(num_users, num_anime, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation.

Selanjutnya proses training.
"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""### Visualisasi Metrik

visualisasi plot metrik evaluasi dengan matplotlib. Terapkan kode berikut.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""proses training model cukup smooth dan model konvergen pada epochs sekitar 100. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.06 untuk training dan error pada data validasi sebesar 0.25. Nilai tersebut cukup bagus untuk sistem rekomendasi.

### Mendapatkan Rekomendasi Anime

mendapatkan rekomendasi Anime, dengan mengambil sampel user secara acak dan definisikan variabel anime_not_visited yang merupakan daftar Anime yang belum pernah dikunjungi oleh pengguna. karena daftar anime_not_visited inilah yang akan menjadi Anime yang kita rekomendasikan.

Sebelumnya, pengguna telah memberi rating pada beberapa Anime yang telah mereka kunjungi. Kita menggunakan rating ini untuk membuat rekomendasi anime yang mungkin cocok untuk pengguna. Nah, anime yang akan direkomendasikan tentulah anime yang belum pernah dikunjungi oleh pengguna. Oleh karena itu, kita perlu membuat variabel anime_not_visited sebagai daftar anime untuk direkomendasikan pada pengguna.

Variabel anime_not_visited diperoleh dengan menggunakan operator bitwise (~) pada variabel anime_visited_by_user.

dengan kode di bawah,
"""

anime_df = fix_anime
df = example_rating

anime_df

df

# Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
anime_visited_by_user = df[df.user_id == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
anime_not_visited = anime_df[~anime_df['anime_id'].isin(anime_visited_by_user.anime_id.values)]['anime_id']
anime_not_visited = list(
    set(anime_not_visited)
    .intersection(set(anime_to_anime_encoded.keys()))
)

anime_not_visited = [[anime_to_anime_encoded.get(x)] for x in anime_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_visited), anime_not_visited)
)

"""untuk memperoleh rekomendasi anime, gunakan fungsi model.predict() dari library Keras dengan menerapkan kode berikut."""

ratings = model.predict(user_anime_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_visited[x][0]) for x in top_ratings_indices
]

print('Menampilkan rekomendasi untuk pengguna: {}'.format(user_id))
print('===' * 15)
print('Anime dengan rating tertinggi dari pengguna')
print('---' * 15)

top_anime_user = (
    anime_visited_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)

anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.Name, ':', row.Genres)

print('---' * 15)
print('Rekomendasi 10 anime teratas')
print('---' * 15)

recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.Name, ':', row.Genres)

"""hasil di atas adalah rekomendasi untuk user dengan id 75809. Dari output tersebut, kita dapat membandingkan antara Anime dengan rating tertinggi dari pengguna dan Rekomendasi 10 anime teratas untuk user.

beberapa Anime rekomendasi menyediakan Genre yang sesuai dengan rating user. Kita memperoleh 1 rekomendasi anime dengan Genre Comedy, Drama, Romance.
"""