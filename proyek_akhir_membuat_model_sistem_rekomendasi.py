# -*- coding: utf-8 -*-
"""Proyek Akhir : Membuat Model Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uWBvP30OULcHSPHuPGuIlh3MhD2jFHsF

# Recommendation System : Anime

![anime](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11299784%2Fcaaff69976c0a1e97c7d55eb82383680%2Fstatic-assets-upload6207184415643227018.jpg?generation=1686492418151095&alt=media)

## Import Library
"""

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tflw
from tensorflow import keras
from google.colab import files
import matplotlib.pyplot as plt
from tensorflow.keras import layers
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from google.colab import drive
drive.mount('/content/drive')

"""## Data Collection"""

!pip install -q kaggle

!kaggle datasets download -d dbdmobile/myanimelist-dataset

"""## Data Understanding

adalah tahap dalam proses analisis data yang bertujuan untuk memahami dataset secara mendalam sebelum melakukan analisis lebih lanjut.

### Data Loading

Data Loading merupakan tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.

<br>


**Informasi Datasets**


| Jenis    | Keterangan                                                |
|----------|-----------------------------------------------------------|
| Title    | Anime Dataset 2023                                        |
| Source   |[Kaggle](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset/data?select=anime-filtered.csv)                                                  |
| Maintainer | [Sajid](https://www.kaggle.com/dbdmobile)                                                   |
| License  | Database: Open Database, Contents: Database Contents      |
| Visibility | Publik                                                  |
| Tags     | Arts and Entertainment, Movies and TV Shows, Anime and Manga, Popular Culture, Japan |
| Usability | 10.00                                                     |
"""

path = '/content/drive/MyDrive/Submission Dicoding Sistem Rekomendasi/myanimelist-dataset.zip'
extract_to = '/content'

import zipfile

with zipfile.ZipFile(path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

anime_data = pd.read_csv('/content/anime-dataset-2023.csv')
user_detail = pd.read_csv('/content/users-details-2023.csv')
user_rating = pd.read_csv('/content/users-score-2023.csv')

anime_data.head()

user_detail.head()

user_rating.head()

"""### Exploratory Data Analysis - Deskripsi Variabel"""

anime_data.info()

user_detail.info()

user_rating.info()

anime_data.describe()

user_detail.describe()

user_rating.describe()

anime_data.shape

user_detail.shape

user_rating.shape

"""Dari Output diatas didapat informasi:
<br>

| Nama Dataset           | Jumah Baris             | Jumlah Kolom |
|------------------------|-------------------------|--------------|
| anime-dataset-2023.csv | 24905                   | 24            |

<br>

| Nama Dataset           | Jumah Baris             | Jumlah Kolom |
|------------------------|-------------------------|--------------|
| users-details-2023.csv | 731290                  | 16            |

<br>

| Nama Dataset           | Jumah Baris             | Jumlah Kolom |
|------------------------|-------------------------|--------------|
| users-score-2023.csv   | 24325191                | 5            |

### Exploratory Data Analysis - Menangani Missing Value
"""

anime_data.duplicated().sum()

user_detail.duplicated().sum()

user_rating.duplicated().sum()

"""setelah dicek tidak terdapat data yang duplicated pada ke-3 file tersebut"""

anime_data.isnull().sum()

user_detail.isnull().sum()

user_rating.isnull().sum()

"""dari output diatas didapati bahwa terdapat missing value pada dataset user_detail pada atribut Username dengan jumlah 1
, Gender berjumlah 506907, Birthday berjumlah 563222, Location berjumlah 578485 dan pada dataset user rating missing value berjumlah 232 pada atribut username.
"""

user_detail.dropna()

user_rating.dropna()

user_detail.shape

user_rating.shape

"""total data setelah menghapus missig value seperti table berikut:

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 731290 | 16 |

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 24325191 | 5 |

### Exploratory Data Analysis - Univariate Analysis
"""

plt.figure(figsize=(15, 5))
sns.countplot(x=anime_data['Type'], data=anime_data, order=anime_data['Type'].value_counts().index, palette='Set3')
plt.title('Jumlah Type Anime ')
plt.xlabel('Type Anime')
plt.ylabel('Count')
plt.show()

"""Dari visualisasi diatas dapat dilihat pada dataset Type Anime TV menduduki jumlah paling tinggi disusul Movie dan OVA dan paling lalu ada Type anime UNKNOWN dengan jumlah paling sedikit"""

# Menghitung jumlah studios
studio_counts = anime_data['Studios'].value_counts()

# Mengelompokkan studios dengan jumlah terbanyak
top_studios = studio_counts.head(5)  # Mengambil 5 studio teratas
other_count = studio_counts.iloc[5:].sum()  # Menghitung total untuk studio lainnya
studio_counts_grouped = pd.concat([top_studios, pd.Series({'Lainnya': other_count})])  # Menggabungkan dengan pd.concat()

# Membuat pie chart
plt.figure(figsize=(15, 5))
plt.pie(studio_counts_grouped, labels=studio_counts_grouped.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set3', n_colors=len(studio_counts_grouped)))
plt.title('Distribusi Studios Anime (Top 5 + Lainnya)')
plt.axis('equal')  # Equal aspect ratio ensures that pie chart is a circle.
plt.show()

"""Pada Visualisasi Top 5 distribusi Studio Anime terbanyak pada dataset sebesar 42.3% Tidak diketahu (UNKNOWN) lalu 3,3% untuk Studio Toei Animation, 2.1% Studio Sunrise, 1.5% Studio J.C.Staff, 1.3% Shanghai Animation Film Studio dan 49.4% untuk studio lainnya."""

# Data 10 anime teratas berdasarkan jumlah members
top10_anime = anime_data.nlargest(10, 'Members')[['Name', 'Members']]

# Menggunakan palet warna dari Seaborn
colors = sns.color_palette('Set3', n_colors=10)

# Plot bar horizontal
plt.figure(figsize=(15, 5))
plt.barh(top10_anime['Name'], top10_anime['Members'], color=colors * (len(top10_anime) // len(colors) + 1), edgecolor='black')
plt.xlabel('Jumlah Members', fontsize=15)
plt.ylabel('Nama Anime', fontsize=15)
plt.title("10 Anime Teratas Berdasarkan Jumlah Members")
plt.grid(axis='x', linestyle='--', alpha=0.7)

plt.show()

"""dari visualisasi diatas dapat dilihat top 10 anime teratas berdasarkan jumlah membernya mulai dari shingeki no kyojin hingga hunter x hunter."""

# Ubah 'Score' menjadi numerik, abaikan nilai yang tidak bisa dikonversi
anime_data['Score'] = pd.to_numeric(anime_data['Score'], errors='coerce')

# Hapus baris dengan nilai NaN di kolom 'Score'
anime_data = anime_data.dropna(subset=['Score'])

# Data 10 anime teratas berdasarkan 'Score'
top10_anime = anime_data.nlargest(10, 'Score')[['Name', 'Score']]

# Menggunakan palet warna dari Seaborn
colors = sns.color_palette('Set3', n_colors=len(top10_anime))  # Mengambil warna dari palet

# Plot bar horizontal
plt.figure(figsize=(15, 5))
plt.barh(top10_anime['Name'], top10_anime['Score'], color=colors, edgecolor='black')
plt.xlabel('Score', fontsize=15)
plt.ylabel('Nama Anime', fontsize=15)
plt.title("Top 10 Anime Berdasarkan Score Paling Tinggi")
plt.grid(axis='x', linestyle='--', alpha=0.7)

plt.show()

"""dari visualisasi diatas dapat dilihat top 10 anime teratas berdasarkan skor paling tinggi jika diambil 10 teratas berdasarkan score maka hasilnya berbeda dengan 10 anime teratas berdasarkan jumlah membernya.

### Exploratory Data Analysis - Multivariate Analysis
"""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Members', 'Popularity']].corr()

print("Korelasi antara Members dan Popularity:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Popularity
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Members', y='Popularity', alpha=0.6)
plt.title('Scatter Plot of Members vs Popularity')
plt.xlabel('Members')
plt.ylabel('Popularity')
plt.show()

"""Nilai korelasi negatif sebesar -0.36 menunjukkan adanya hubungan negatif sedang antara jumlah Members dan Popularity. Ini berarti bahwa anime dengan jumlah Members yang lebih tinggi cenderung memiliki nilai Popularity yang lebih rendah."""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Favorites', 'Popularity']].corr()

print("Korelasi antara Members dan Popularity:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Popularity
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Favorites', y='Popularity', alpha=0.6)
plt.title('Scatter Plot of Favorites vs Popularity')
plt.ylabel('Favorites')
plt.xlabel('Popularity')
plt.show()

""" Nilai korelasi negatif ini menunjukkan hubungan yang lemah antara jumlah Favorites dan Popularity. Korelasi negatif berarti bahwa ketika jumlah Favorites meningkat, nilai Popularity (peringkat) cenderung menurun, meskipun hubungannya tidak kuat."""

# Menghitung korelasi antara 'Members' dan 'Popularity'
correlation = anime_data[['Favorites', 'Members']].corr()

print("Korelasi antara Members dan Members:")
print(correlation)

# Visualisasi scatter plot untuk melihat hubungan antara Members dan Members
plt.figure(figsize=(10, 6))
sns.scatterplot(data=anime_data, x='Favorites', y='Members', alpha=0.6)
plt.title('Scatter Plot of Favorites vs Members')
plt.ylabel('Favorites')
plt.xlabel('Members')
plt.show()

"""Nilai korelasi 0.773 menunjukkan adanya hubungan positif yang kuat antara jumlah Favorites dan Members. Ini berarti bahwa anime dengan jumlah Members yang tinggi cenderung juga memiliki jumlah Favorites yang tinggi.

### Data Preprocessing

sebelumnya kita memiliki 3 file csv dan setelah di cek untuk melakukan Content Based Filtering kita cukup menggunakan dataset anime-dataset-2023 dan untuk Collaborative Filtering kita cukup menggunakan users-score-2023 yang kemudian akan kita simpan kedalam 2 data frame Anime dan Rating.

**Hapus beberapa atribut yang tidak terlalu penting pada data Anime**
"""

print("Daftar Atribut:")
print(anime_data.columns.tolist())

Anime = anime_data.drop(columns=[
    'English name', 'Other name', 'Synopsis','Episodes', 'Aired', 'Premiered',
    'Status', 'Producers', 'Licensors', 'Studios', 'Source', 'Duration', 'Rating',
    'Rank', 'Popularity', 'Favorites', 'Scored By', 'Members', 'Image URL', 'Score','Type'
    ])

"""**Hapus beberapa atribut yang tidak terlalu penting pada data Rating**"""

print("Daftar Atribut:")
print(user_rating.columns.tolist())

Rating = user_rating.drop(columns=[
    'Anime Title',
    'Username'
])

"""**Menyamakan Anime Genres**"""

fix_anime = Anime.sort_values('anime_id', ascending=True)
fix_anime

"""Sekarang, kita memiliki 15692 baris data."""

# Mengecek Genres yang unik
fix_anime.Genres.unique()

fix_anime[fix_anime['Genres'] == 'UNKNOWN']

fix_anime = fix_anime[fix_anime['Genres'] != 'UNKNOWN']

"""karena kita akan membangun sistem rekomendasi anime berdasarkan genre anime untuk value genres UNKNOWN kita hapus."""

fix_rating = Rating.sample(n=10000, random_state=42)

print(fix_rating.head())

example_rating = fix_rating.copy()
print(example_rating.head())

"""karena dataset Rating sangat banyak dan tidak sepadan dengan sumber daya yang saya miliki oleh karena itu kita akan mengambil beberap puluh ribu saja untuk dijadikan sample.

## Data Preparation

Teknik Data preparation yang dilakukan terdiri dari:

- TF-IDF Vectorizer Data Anime
- Encoding Data User Rating
- Train-test-split User Rating

### TF-IDF Vectorizer Data Anime

seperti yang kita ketahui komputer hanya bisa memproses data numerik oleh karena itu kita perlu mengubah nilai genres menjadi numerik dengan TfidfVectorizer,
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(fix_anime['Genres'])

tf.get_feature_names_out()

"""Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks."""

tfidf_matrix = tf.fit_transform(fix_anime['Genres'])

tfidf_matrix.shape

"""matriks yang kita miliki berukuran (13939, 27). Nilai 13939 merupakan ukuran data dan 27 merupakan genres anime.

Untuk menghasilkan vektor tf-idf dalam bentuk matriks, kita menggunakan fungsi todense(). Jalankan kode berikut.
"""

tfidf_matrix.todense()

"""Selanjutnya, mari kita lihat matriks tf-idf untuk beberapa anime dan genresnya. dengan kode berikut."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=fix_anime.Name
).sample(27, axis=1).sample(10, axis=0)

"""### Encoding Data User Rating"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = fix_rating['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

"""Selanjutnya, lakukan hal yang sama pada fitur ‘anime_id’."""

anime_ids = fix_rating['anime_id'].unique().tolist()

anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}

anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

"""Berikutnya, petakan user_id dan anime_id ke dataframe yang berkaitan."""

fix_rating['user'] = fix_rating['user_id'].map(user_to_user_encoded)

fix_rating['anime'] = fix_rating['anime_id'].map(anime_to_anime_encoded)

"""dan terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah anime, dan mengubah nilai rating menjadi float."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah anime
num_anime = len(anime_encoded_to_anime)
print(num_anime)

# Mengubah rating menjadi nilai float
fix_rating['rating'] = fix_rating['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(fix_rating['rating'])

# Nilai maksimal rating
max_rating = max(fix_rating['rating'])

print('Number of User: {}, Number of anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

fix_rating

"""### Train-test-split User Rating"""

fix_rating = fix_rating.sample(frac=1, random_state=42)
fix_rating

"""lalu membagi data train dan validasi dengan komposisi 80:20. Namun sebelumnya, kita perlu memetakan (mapping) data user dan anime menjadi satu value terlebih dahulu. dan membuat rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training"""

# Membuat variabel x untuk mencocokkan data user dan anime menjadi satu value
x = fix_rating[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = fix_rating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * fix_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## Model and Result

Pada tahapan model yang digunakan terdiri dari:

- Cosine Similarity
- recomenderNet

### Model Development dengan Cosine Similarity

selanjutnya menghitung derajat kesamaan (similarity degree) antar anime dengan teknik cosine similarity. Di sini, kita menggunakan fungsi cosine_similarity dari library sklearn dengan kode berikut.
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""tahapan ini, menghitung cosine similarity dataframe tfidf_matrix yang kita peroleh pada tahapan sebelumnya. Dengan satu baris kode untuk memanggil fungsi cosine similarity dari library sklearn, jika sudah selesai menghitung kesamaan (similarity) antar restoran. Kode di atas menghasilkan keluaran berupa matriks kesamaan dalam bentuk array."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=fix_anime['Name'], columns=fix_anime['Name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dengan cosine similarity, kita berhasil mengidentifikasi kesamaan antara satu anime dengan anime lainnya. Shape (13939, 13939) merupakan ukuran matriks similarity dari data yang kita miliki. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 13939 anime x 13939 anime (masing-masing dalam sumbu X dan Y). Artinya, kita mengidentifikasi tingkat kesamaan pada 13939 nama anime.

**Hasil Rekomendasi Model Cosine Similarity Top-N**

Sebelumnya, hasil data similarity (kesamaan) antar anime, selanjutnya menghasilkan sejumlah anime yang akan direkomendasikan kepada pengguna.

Di sini, kita membuat fungsi anime_recommendations dengan beberapa parameter sebagai berikut:

Nama_anime : Nama anime (index kemiripan dataframe). Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya. Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘anime_name’ dan ‘’.Genres k : Banyak rekomendasi yang ingin diberikan. Sebelum mulai menulis kodenya, ingatlah kembali definisi sistem rekomendasi yang menyatakan bahwa keluaran sistem ini adalah berupa top-N recommendation.
"""

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=fix_anime[['Name', 'Genres']], k=10):

    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_anime agar nama anime yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_anime, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""pada kode di atas, dengan menggunakan argpartition, kita mengambil sejumlah nilai k tertinggi dari similarity data (dalam kasus ini: dataframe cosine_sim_df). Kemudian, kita mengambil data dari bobot (tingkat kesamaan) tertinggi ke terendah. Data ini dimasukkan ke dalam variabel closest. Berikutnya, kita perlu menghapus nama_anime yang yang dicari agar tidak muncul dalam daftar rekomendasi. Dalam kasus ini, nanti kita akan mencari anime yang mirip dengan Tarareba, sehingga kita perlu drop nama_anime Tarareba agar tidak muncul dalam daftar rekomendasi yang diberikan nanti."""

fix_anime[fix_anime.Name.eq('Hajimete no Gal')]

"""Hasil Output di atas, `Hajimete no Gal` masuk dalam Genre `Comedy, Romance, Ecchi`. Tentu kita berharap rekomendasi yang diberikan adalah resto dengan kategori yang mirip. Nah, sekarang, dapatkan anime recommendation dengan memanggil fungsi yang telah kita definisikan sebelumnya:"""

anime_recommendations('Hajimete no Gal')

"""Sistem kita memberikan rekomendasi 10 anime dengan genre `Comedy, Romance, Ecchi`.

### Model Development dengan RecommenderNet

model menghitung skor kecocokan antara pengguna dan anime dengan teknik embedding, melakukan proses embedding terhadap data user dan anime. Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan anime. Selain itu, kita juga dapat menambahkan bias untuk setiap user dan anime. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.

membuat class RecommenderNet dengan keras Model class. Kode class RecommenderNet ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang kita selesaikan. Terapkan kode berikut.
"""

class RecommenderNet(tflw.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = layers.Embedding( # layer embeddings anime
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) # layer embedding anime bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    anime_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    anime_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_anime = tflw.tensordot(user_vector, anime_vector, 2)

    x = dot_user_anime + user_bias + anime_bias

    return tflw.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, melakukan proses compile terhadap model."""

model = RecommenderNet(num_users, num_anime, 50) # inisialisasi model

# model compile
model.compile(
    loss = tflw.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tflw.keras.metrics.RootMeanSquaredError()]
)

"""Menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation.

**Training Model**
"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**Hasil Rekomendasi Model RecommenderNet Top-N**

mendapatkan rekomendasi Anime, dengan mengambil sampel user secara acak dan definisikan variabel anime_not_visited yang merupakan daftar Anime yang belum pernah dikunjungi oleh pengguna. karena daftar anime_not_visited inilah yang akan menjadi Anime yang kita rekomendasikan.

Sebelumnya, pengguna telah memberi rating pada beberapa Anime yang telah mereka kunjungi. Kita menggunakan rating ini untuk membuat rekomendasi anime yang mungkin cocok untuk pengguna. Nah, anime yang akan direkomendasikan tentulah anime yang belum pernah dikunjungi oleh pengguna. Oleh karena itu, kita perlu membuat variabel anime_not_visited sebagai daftar anime untuk direkomendasikan pada pengguna.

Variabel anime_not_visited diperoleh dengan menggunakan operator bitwise (~) pada variabel anime_visited_by_user.

dengan kode di bawah,
"""

anime_df = fix_anime
df = example_rating

# Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
anime_visited_by_user = df[df.user_id == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
anime_not_visited = anime_df[~anime_df['anime_id'].isin(anime_visited_by_user.anime_id.values)]['anime_id']
anime_not_visited = list(
    set(anime_not_visited)
    .intersection(set(anime_to_anime_encoded.keys()))
)

anime_not_visited = [[anime_to_anime_encoded.get(x)] for x in anime_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_visited), anime_not_visited)
)

ratings = model.predict(user_anime_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_visited[x][0]) for x in top_ratings_indices
]

print('Menampilkan rekomendasi untuk pengguna: {}'.format(user_id))
print('===' * 15)
print('Anime dengan rating tertinggi dari pengguna')
print('---' * 15)

top_anime_user = (
    anime_visited_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)

anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.Name, ':', row.Genres)

print('---' * 15)
print('Rekomendasi 10 anime teratas')
print('---' * 15)

recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.Name, ':', row.Genres)

"""hasil di atas adalah rekomendasi untuk user dengan id 75809. Dari output tersebut, kita dapat membandingkan antara Anime dengan rating tertinggi dari pengguna dan Rekomendasi 10 anime teratas untuk user.

beberapa Anime rekomendasi menyediakan Genre yang sesuai dengan rating user. Kita memperoleh 1 rekomendasi anime dengan Genre Comedy, Drama, Romance.

## Evaluasi Model

### Visualisasi Matrix Root mean squared error (RMSE)
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""proses training model cukup smooth dan model konvergen pada epochs sekitar 100. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.06 dan error pada data validasi sebesar 0.25. Nilai tersebut cukup bagus untuk sistem rekomendasi.

### Matrix Precision

menggunakan metrik Precision untuk mengetahui seberapa baik perforam model tersebut. Presisi adalah metrik yang biasa digunakan untuk mengevaluasi kinerja model pengelompokan. Metrik ini menghitung rasio antara nilai ground truth (nilai sebenarnya) dengan nilai prediksi yang positf. Perhitungan rasio ini dijabarkan melalui rumus di bawah ini:

$$ Precision = \frac{TP}{TP + FP} $$

Dimana:

- TP (*True Positive*), jumlah kejadian positif yang diprediksi dengan benar.
- FP (*False Positive*), jumlah kejadian positif yang diprediksi dengan salah.

Berdasarkan hasil yang dikeluarkan model `Cosine Similiarity` sebelumnya dapat dilihat bahwasanya besar presisi jika dihitung adalah 10/10 untuk rekomendasi Top-10. Ini menunjukan sistem mampu memberikan rekomendasi sesuai dengan Genres Animenya.
"""